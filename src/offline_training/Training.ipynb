{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training process of Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xgboost as xgb\n",
    "import numpy\n",
    "from calibration import calibrators, plots\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pandas.read_csv(\"../../data/processed_data/training_set.csv\")\n",
    "validation_set = pandas.read_csv(\"../../data/processed_data/validation_set.csv\")\n",
    "testing_set = pandas.read_csv(\"../../data/processed_data/testing_set.csv\")\n",
    "calibration_set = pandas.read_csv(\"../../data/processed_data/calibration_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\n",
    "    training_set,\n",
    "    validation_set,\n",
    "    testing_set,\n",
    "    calibration_set\n",
    "]:\n",
    "    dataset.drop(\n",
    "        columns=[\n",
    "            \"Unnamed: 0\",\n",
    "            \"Unnamed: 0.1\"\n",
    "        ], inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Calibration set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = calibration_set.drop(columns=['bad_client']), calibration_set['bad_client']\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=100\n",
    ")\n",
    "\n",
    "train_calibration_set = pandas.concat([x_train, y_train], axis=1)\n",
    "test_calibration_set = pandas.concat([x_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = training_set.drop(columns=['bad_client'])\n",
    "y_train = training_set['bad_client']\n",
    "\n",
    "loss_function = make_scorer(log_loss, greater_is_better=False)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    estimator=model,\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    n_jobs=-1,\n",
    "    cv=StratifiedKFold(n_splits=10),\n",
    "    scoring=loss_function\n",
    ")\n",
    "# Checking model training loss\n",
    "cv_score = numpy.mean(cv_results['test_score'])\n",
    "print('loss: %s' % cv_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "}\n",
    "\n",
    "X_validation = validation_set.drop(columns=['bad_client'], inplace=False)\n",
    "Y_validation = validation_set['bad_client']\n",
    "\n",
    "loss_function = make_scorer(log_loss, greater_is_better=False)\n",
    "tuned_model = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=hyperparams,\n",
    "    scoring=loss_function,\n",
    "    n_jobs=-1,\n",
    "    cv=StratifiedKFold(n_splits=5)\n",
    ")\n",
    "# Fitting model\n",
    "tuned_model.fit(X_validation, Y_validation)\n",
    "chosen_model = tuned_model.best_estimator_\n",
    "loss = tuned_model.best_score_\n",
    "print('hyperparameter validation loss: %s' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_calibration = train_calibration_set.drop(columns=['bad_client'])\n",
    "y_train_calibration_proba = pandas.Series(chosen_model.predict_proba(x_train_calibration)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Calibration quality of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.calibration_plot(\n",
    "    y_true=train_calibration_set['bad_client'],\n",
    "    y_pred=y_train_calibration_proba,\n",
    "    bins=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Training Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_train_dataset = calibrators.CalibrationDataset(\n",
    "    decision_scores=y_train_calibration_proba.to_numpy().tolist(),\n",
    "    true_classes=train_calibration_set['bad_client'].to_numpy().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platt_scaler = calibrators.PlattScaling()\n",
    "\n",
    "# training calibration algorithm\n",
    "platt_scaler.train(\n",
    "    train_dataset=calibration_train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Testing Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting decision scores from given testing calibration data\n",
    "x_test_calibration = test_calibration_set.drop(columns=['bad_client'])\n",
    "predicted_test_calibration_scores = chosen_model.predict_proba(x_test_calibration)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating calibration dataset\n",
    "\n",
    "calibration_test_dataset = calibrators.CalibrationDataset(\n",
    "    decision_scores=predicted_test_calibration_scores.tolist(),\n",
    "    true_classes=test_calibration_set['bad_client'].to_numpy().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating Calibration Algorihtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = pandas.Series(calibration_test_dataset.true_classes)\n",
    "predicted_probs = pandas.Series(platt_scaler.get_calibrated_prob(\n",
    "    decision_scores=calibration_test_dataset.decision_scores\n",
    "))\n",
    "\n",
    "plots.calibration_plot(\n",
    "    y_true=true_classes,\n",
    "    y_pred=predicted_probs,\n",
    "    bins=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing ML model on a Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testing_set.drop(columns=['bad_client'])\n",
    "Y_test = testing_set['bad_client']\n",
    "\n",
    "def eval_f1_macro(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Standard F1 Score metric with weighted average\n",
    "    \"\"\"\n",
    "    return f1_score(\n",
    "        y_true, y_pred,\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "eval_function = make_scorer(eval_f1_macro, greater_is_better=True)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    estimator=chosen_model,\n",
    "    X=X_test,\n",
    "    y=Y_test,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    scoring=eval_function,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print('F1 Score: %s' % numpy.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(chosen_model, open('../models/classifier.pkl', mode='wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Calibration Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(platt_scaler, open(\"../calibrators/platt_calibrator.pkl\", mode='wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c9d868ccd008ea04b9c5a002fb183b0949d8c1b424380ded90a0df80fb5d714"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
